---
title: "T08 - ERGM3"
description: "Bipartite and Weighted ERGMs in the R language"
output: 
  learnr::tutorial:
    fig_caption: no
    progressive: true
    allow_skip: true
    toc: true
    toc_depth: 3
    theme: readable
runtime: shiny_prerendered
---



```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(ergm)

knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	cache = FALSE
)

source("../R/helper_code.R")

# Check whether required packages are installed
pkgs <- matrix(c(
  "learnr", "0.10.2", "CRAN",
  "gradethis", "0.2.8.9000", "rstudio/gradethis",
  "igraph", "1.3.2", "CRAN",
  "knitr", "1.39", "CRAN",
  "sna", "2.7", "CRAN",
  "SNA4DSData", "0.9.91", "SNAnalyst/SNA4DSData",
  "ergm", "4.1.2", "CRAN",
  "network","1.17.1" , "CRAN",
  "texreg", "1.38.6" , "CRAN",
  "GERGM", "0.13.0" , "matthewjdenny/GERGM"
), byrow = TRUE, ncol = 3) |> 
  as.data.frame() |> 
  setNames(c("pkg", "version", "where"))

check_pkgs <- function(.pkgs = pkgs) {
  sna4tutti:::check_packages(.pkgs)
}

# RStudio, at least 4.1717
check_RStudio <- sna4tutti:::check_rstudio


# R check version (required 4.2.1) updated August 2022
check_R <- function(x) {
  sna4tutti:::check_r_equal(4,2.1)
}

errors <- list()

```


```{css, echo = FALSE}
.tip {
  border-radius: 10px;
  padding: 10px;
  border: 2px solid #136CB9;
  background-color: #136CB9;
  background-color: rgba(19, 108, 185, 0.1);
  color: #2C5577;
}

.warning {
  border-radius: 10px;
  padding: 10px;
  border: 2px solid #f3e2c4;
  background-color: #f3e2c4;
  background-color: rgba(243, 226, 196, 0.1);
  color: #775418;
}

.infobox {
  border-radius: 10px;
  padding: 10px;
  border: 2px solid #868e96;
  background-color: #868e96;
  background-color: rgba(134, 142, 150, 0.1);
  color: #2F4F4F;
}

# # create a horizontal scroll bar when code is too wide
# pre, code {white-space:pre !important; overflow-x:auto}
```

```{html, echo = FALSE}
<style>
pre {
  white-space: pre-wrap;
  background: #F5F5F5;
  max-width: 100%;
  overflow-x: auto;
}
</style>
```


## Introduction 

Since now you rock the basic one, welcome to the magical mystery tour on advanced ERGMs!

In this tutorial, we are going to cover two types of advanced ERGMs. First, the bipartite. It can be specified as a particular option of the regular ERGM with the `ergm` package. Second, we are going to learn the weighted ERGM, which requires a new package named `GERGM`, standing for Generalized Exponential Random Graph Models

Put your seat belt on, and let's go!

![](images/the-beatles-magical-mystery-tour-album-i56827.jpg){width=75%}

## Packing up for the tour!

Before we start the magical mystery tour, we need to make sure we carry our essentials in the backpack!


### R Version 

You need to have installed R version 4.2.1 and this tutorial is going to check it
for you. Please hit the `Run Code` button.

```{r r_check, echo = TRUE, include = TRUE, exercise = TRUE}
check_R()
```


### R Studio Version

You need to have installed RStudio version 2021.9.0.351 or above.
Let's check by clicking `Run Code`:

```{r rstudio_check, echo = TRUE, include = TRUE, exercise = TRUE}
check_RStudio()
```


### Packages

You need to have a few packages installed. 
Click the `Run Code` to check. 
It will check whether you have the required packages installed and will 
attempt to install any missing packages in case there are any (or it will 
advise you to upgrade `sna4tutti`).

```{r package_check, echo = TRUE, include = TRUE, exercise = TRUE}

check_pkgs()

```


All packed up! Let's roll!!

## The 7-step Research Flow

From now on, when we fit a model, we put it in the context of carrying out actual research. To do so, we rely on the 7-step flow approach introduced in the ERGM2 Lab: 

1. Literature research/ Questions & Hypotheses (based on the literature) [- data collection]
2. Data Exploration + terms selection
3. Running models (baseline, exploratory models, final model)
4. MCMC diagnostics of the model selected as the best
5. Goodness of fit
6. Interpreting results
7. Write up about your research telling how this journey went

Take a look at the image below. It guides you step by step on how to use the flow!

![](images/7stepsFlow.png){width=100%}


## Bipartite ERGMs

Bipartite ERGMs require a bipartite network. DUH!

Just to be clear. A bipartite network has two sets of nodes that can be connected to each other but not within, as in the image below.

![](images/Simple-bipartite-graph.png){width=75%}

Even if the concept of bipartite network is pretty straightforward, 
Setting up your network as a bipartite to be ready for a bipartite ERGM with the `ergm` package is not that simple. 

Let's see how to do it step by step. 

### Setting up a network as bipartite

Both unimodal and bipartite networks can be expressed as node lists, but while unimodal networks can also be represented by adjacency matrices, bipartite networks require _incidence matrices_.

While adjacency matrices are squared, with the same items in rows and columns, incidence matrices have the first set of elements in rows and the second set in columns. Hence if we have a bipartite network of 10 friends going to Cinema Club four times in total, we will get an incidence matrix of 10 by 4 elements. 

You can import a bipartite network in the `network` package (that we need to run ERGMs with the `ergm` package) both using the edge list and the incidence matrix. 

Let's see how to do it with an incidence matrix. 

```{r load_IncMat, include = FALSE}

mdata <- matrix(c(1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1), 10, 4)

vertex.names <- c(LETTERS[1:10], 1:4)

Age <- c(6, 7, 7, 7, 9, 9, 10, 9, 12, 12, NA, NA, NA, NA)

Gender <- as.character(c(0, 0, 0, 0, 0, 1, 1, 1, 1, 1, NA, NA, NA, NA))

kidsnet <- network::network(mdata, directed = FALSE, bipartite = TRUE)

```


```{r test_load_IncMat1, results = 'markup'}

mdata <- matrix(c(1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1), 10, 4)
vertex.names <- c(LETTERS[1:10], 1:4)
kidsnet <- network::network(mdata, directed = FALSE, bipartite = TRUE)

if (base::isFALSE(sum(network::get.vertex.attribute(kidsnet, 'vertex.names')) == 105)) {
  sna4tutti::broken_info()
  error <- knitr::opts_current$get(name = "label")
  errors <- base::append(errors, error)
}

```

Let's take a look at our incidence matrix 

```{r bip01, exercise = TRUE, exercise.setup = "load_IncMat"}
mdata
```

Our first set of nodes (rows) is constituted by 10 kids, while our second set is constituted by 4 playdates the kids go to (columns). 

Let's turn it into a `network` object. We need to specify that it is a bipartite and undirected network.


```{r bip02, exercise = TRUE, exercise.setup = "load_IncMat"}
kidsnet <- network::network(mdata, directed = FALSE, bipartite = TRUE)
kidsnet
```

Ok, we are done! Is this enough? Well, no. Let's insert attributes. Shall we? 

We already have three attributes stored in 3 vectors, respectively called "vertex.names", "Age", "Gender". 

We simply need to include them in the `network` object.

```{r bip03, exercise = TRUE, exercise.setup = "load_IncMat"}

network::set.vertex.attribute(kidsnet, "vertex.names",  vertex.names)
network::set.vertex.attribute(kidsnet, "Age",  Age)
network::set.vertex.attribute(kidsnet, "Gender",  Gender)

kidsnet
```


```{r test_load_IncMat2, results = 'markup'}

mdata <- matrix(c(1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1), 10, 4)
vertex.names <- c(LETTERS[1:10], 1:4)
kidsnet <- network::network(mdata, directed = FALSE, bipartite = TRUE)

Age <- c(6, 7, 7, 7, 9, 9, 10, 9, 12, 12, NA, NA, NA, NA)
Gender <- as.character(c(0, 0, 0, 0, 0, 1, 1, 1, 1, 1, NA, NA, NA, NA))

network::set.vertex.attribute(kidsnet, "vertex.names",  vertex.names)
network::set.vertex.attribute(kidsnet, "Age",  Age)
network::set.vertex.attribute(kidsnet, "Gender",  Gender)

if (base::isFALSE(network::get.vertex.attribute(kidsnet, 'vertex.names')[1] == "A" &
            network::get.vertex.attribute(kidsnet, 'vertex.names')[4] == "D" &
            network::get.vertex.attribute(kidsnet, 'Age')[3] == 7 &
            network::get.vertex.attribute(kidsnet, 'Age')[7] == 10 &
            network::get.vertex.attribute(kidsnet, 'Gender')[1] == 0 &
            network::get.vertex.attribute(kidsnet, 'Gender')[8] == 1)) {
  sna4tutti::broken_info()
  error <- knitr::opts_current$get(name = "label")
  errors <- base::append(errors, error)
}

```




At this point, you might really think we are done. Are we? In fact, we are not. We need to pass an extra attribute to the network so that it is crystal clear that we are dealing with a bipartite. 

We are going to code an attribute named _"bipartite"_. The bipartite attribute needs to have the same dimension as the first partition. So in our case, it will be 10.
 


```{r bip04readynet, exercise = TRUE, exercise.setup = "bip03"}

network::set.vertex.attribute(kidsnet, "bipartite", value = rep(10, 10), v = 1:10)

kidsnet
```

Now we are done and ready to crunch some numbers!


### Fitting bipartite ERGMs 

Let's fit Bipartite ERGMs using the 7-step flows!

#### Step One

As world experts in children behavior and play-date-ology (just kidding!), we are fully aware of the literature, and we specify three hypotheses

1. Older kids go to more playdates
2. There is homophily by gender (girls play with girls, boys play with boys)
3. Some play dates have more attendees than others (some sort of popularity effect)

#### Step two

Let's Inspect our data. 

First, we should get to know our attributes.

```{r bip05, exercise = TRUE, exercise.setup = "bip04readynet"}

network::get.vertex.attribute(kidsnet, "Age")
class(network::get.vertex.attribute(kidsnet, "Age"))

network::get.vertex.attribute(kidsnet, "Gender")
class(network::get.vertex.attribute(kidsnet, "Gender"))



```

Do you see those NAs at the end of the vectors? The reason why there are there is because the attributes make sense only for kids and not for play dates, but `network` stores information in this way. Be careful to understand the data architecture of bipartite graphs in `network`; otherwise, you might get into errors that require painful debugging sessions!



Then, we get acquainted with some network structural features, such as degree

```{r bip06, exercise = TRUE, exercise.setup = "bip04readynet"}


# Total degree
summary(kidsnet ~ degree(1:10))

# Degree partition 1 (kids)
summary(kidsnet ~ b1degree(1:10))

# Degree partition 2 (play-dates)
summary(kidsnet ~ b2degree(1:10))

```

and stars


```{r bip06_01, exercise = TRUE, exercise.setup = "bip04readynet"}


# Total 2 to 10 stars
summary(kidsnet ~ kstar(2:10))

# 2 to 4 stars partition 1 (kids) --- max 4 playdates (max possible degree)
summary(kidsnet ~ b1star(2:4))

# 2 to 10  stars partition 2 (play-dates) --- max 10 kids (maximum possible degree)
summary(kidsnet ~ b2star(2:10))

```

Have you realized that you can specify the effects both focusing on one partition or the other? Make sure you pay close attention to this!

Hence, we can now specify our terms, 

H1. `b1cov("Age")`
H2. `b1nodematch("Gender")`
H3. some stars or degree terms

Remember that the bipartite terms are different from the unimodal one. The main difference is that you can specify them for one partition or the other, according to your research questions and hypotheses. 

Do you want to explain kids behavior or play dates occurrence? 

You can explore them using the function:

`ergm::search.ergmTerms(categories = 'bipartite')`

#### Step 3


First baseline models and dyadic independent exploratory models


```{r bip07, exercise = TRUE, exercise.setup = "bip04readynet"}

m0 <- ergm::ergm(kidsnet ~ edges)
summary(m0)

m1 <-ergm::ergm(kidsnet ~ edges + b1cov("Age"))
summary(m1)

m2 <-ergm::ergm(kidsnet ~ edges + b1nodematch("Gender"))
summary(m2)


```


Now we can run dyadic dependent exploratory models. Since the dyadic dependent involves a simulation, they are computationally more intense. To reduce the computational time and make the model work better, we can try to do two things. 

First, we should constraint the model. For instance, in the example below, I'm asking the simulation to exclude networks with nodes having degrees lower than 1 (isolate) and larger than 14 (max N nodes) since they would be unrealistic in the current situation that we are exploring.

Second, we can control the model specifying how the simulation should run (but we know how to this already!).

Let's get to it.



```{r bip08, exercise = TRUE, exercise.setup = "bip04readynet"}

m3 <-ergm::ergm(kidsnet ~ edges + b1star(2), 
                constraints = ~ bd(minout = 0, maxout=14),
                control = ergm::control.ergm(MCMC.burnin = 5000,
                                             MCMC.samplesize = 10000,
                                             seed = 1234,
                                             MCMLE.maxit = 20))
summary(m3)


```



Finally, we can run a complete model!

_ALERT:_

THIS MODEL USES PARALLELIZATION. CHECK YOUR NUMBER OF CORES BEFORE RUNNING. 

If you have more than two cores, you can increase the number below and make it faster. 


```{r bip09finMod, exercise = TRUE, exercise.setup = "bip04readynet"}

m4 <-ergm::ergm(kidsnet ~ edges + b1cov("Age") + b1nodematch("Gender") + b1star(2), 
                constraints = ~ bd(minout = 0, maxout=14),
                control = ergm::control.ergm(MCMC.burnin = 5000,
                                             MCMC.samplesize = 10000,
                                             seed = 1234,
                                             MCMLE.maxit = 20,
                                             parallel = 2,
                                             parallel.type = "PSOCK"))
summary(m4)

```


#### Step four

Let's assume that we selected our best model comparing AIC and BIC across them, and we now move on to check the MCMC diagnostics.

Is this model good? By running `ergm::mcmc.diagnostics(m4)` you would get something like the image below


![](images/m4MCMCdianostics.png){width=100%}


If and only if you think that the model is good enough, you can move to the goodness of fit. Otherwise, get back and try a different model specification (getting back to steps 1, 2, 3).



#### Step 5

Is the goodness of fit good? If and only if you think that the model is good enough, you can move to the interpretation of results! Otherwise, get back and try a different model specification (getting back to steps 1, 2, 3).

```{r bip11, exercise = TRUE, exercise.setup = "bip09finMod"}

ergm::gof(m4)

# snafun::stat_plot_gof(m4)

```

Let's assume that it is good enough for now so that we can move on...


#### Step 6

The model we run (m4) seems nice enough to read results according to steps 4 and 5. Ok, let's read the results!

Let's look at coefficients and odd ratios first.

```{r bip12, exercise = TRUE, exercise.setup = "bip09finMod"}


snafun::stat_ef_int(m4, type = "odds")

```

The only significant term in the model is `nodematch` by gender. Interpreting the coefficient, we know that kids of the same gender tend to attend the same playdates. The extent to which kids go to a certain party (form edges) increases if the kids are both girls or boys.

Interpreting the odds ratio ($2.375$), we know that this effect is really strong since the OR is much larger than 1. 

Let's look at probabilities.

```{r bip13, exercise = TRUE, exercise.setup = "bip09finMod"}

snafun::stat_ef_int(m4, type = "prob")

```

Looking at the probabilities, we know that the probability of kids of the same gender attending the same play date is 70.4 % ($0.704*100$). Waw! this is really a strong effect, and it is in line with the OR, just easier to interpret!

### Step 7

Well, in this tutorial, we can skip the step where we write up the results (since I already wrote up all the narratives step by step!), but don't forget to include this step in your future analyses!

Enough about bipartite! We can now move to mystery tour part two: the weighted ERGMs!

## Weighted ERGMs

Here we go with weighted networks! This kind of network is also expressed as an adjacency matrix. Still, rather than having a matrix populated by 0s and 1s, we have a matrix populated by any other number representing a weight. These weights imply that some edges might define stronger relationships than others. 

Even if any graph can have a weight, with weighted ERGMs, we can only analyze fully connected graphs.

The type of weight makes a real difference. 

If the weight attributed to the edges of a fully connected graph is a count variable, we can run an ERGM using a variant of the `ergm` package called `ergm.count`. 

This would work in a situation when we have three waves of friendship data that we recode as 

* friends for 1 year - weight 1
* friends for 2 years - weight 2
* friends for 3 years - weight 3

This is a count variable. The weight must be larger than 0 (non-negative), and it cannot be in between the categories that it describes.

However, weight can express many other realities that need more complex definitions, such as the money export between countries measured in dollars. The `GERGM` package can handle both the count weight and the more complex cases, and for this reason, we are going to move out of the `statnet` environment for this kind of models. 


Let's take a look at a real case study published by 

`James D. Wilson, Matthew J. Denny, Shankar Bhamidi, Skyler Cranmer, and Bruce Desmarais (2017).` 
`“Stochastic weighted graphs: Flexible model specification and simulation”. Social Networks, 49, 37–47.`

We have 17 countries exchanging money with each other (international trade) in 2005.

```{r weightloadData, echo = FALSE}

data("lending_2005", package = "GERGM")
data("covariate_data_2005", package = "GERGM")
data("net_exports_2005", package = "GERGM")

```


```{r test_weightloadData1, results = 'markup'}

data("lending_2005", package = "GERGM")

if (base::isFALSE(base::round(lending_2005[2, 2],3) == 0 &
            base::round(lending_2005[3, 17],3) == 9.096 &
            base::round(lending_2005[4, 2],3) == 7.141 &
            base::round(lending_2005[5, 17],3) == 7.879 &
            base::round(lending_2005[6, 2],3) == 9.985 &
            base::round(lending_2005[7, 17],3) == 12.569 &
            base::round(lending_2005[8, 2],3) == 4.676)) {
  sna4tutti::broken_info()
  error <- knitr::opts_current$get(name = "label")
  errors <- base::append(errors, error)
}

```


```{r test_weightloadData2, results = 'markup'}


data("covariate_data_2005", package = "GERGM")


if (base::isFALSE(base::round(sum(covariate_data_2005[2,1:2],3)) == 693338595730 &
            base::round(sum(covariate_data_2005[3,1:2],3)) == 892106837602 &
            base::round(covariate_data_2005[5, 2],3) == 28.45 &
            base::round(covariate_data_2005[6, 2],3) == 28.421 &
            base::round(covariate_data_2005[7, 2],3) == 28.681 &
            base::round(covariate_data_2005[8, 2],3) == 27.45)) {
  sna4tutti::broken_info()
  error <- knitr::opts_current$get(name = "label")
  errors <- base::append(errors, error)
}

```

```{r test_weightloadData3, results = 'markup'}


data("net_exports_2005", package = "GERGM")

if (base::isFALSE(base::round(sum(net_exports_2005[2,2:17],3)) == 3 &
            base::round(sum(net_exports_2005[3,2:17],3)) == 3 &
            base::round(sum(net_exports_2005[4,2:17],3)) == 3 &
            base::round(sum(net_exports_2005[5,2:17],3)) == 4 &
            base::round(sum(net_exports_2005[6,2:17],3)) == 3 &
            base::round(sum(net_exports_2005[7,2:17],3)) == 4 &
            base::round(sum(net_exports_2005[8,2:17],3)) == 3)) {
  sna4tutti::broken_info()
  error <- knitr::opts_current$get(name = "label")
  errors <- base::append(errors, error)
}

```


This is how this weighted network looks like

```{r weight01, exercise = TRUE, exercise.setup = "weightloadData"}

lending <- igraph::graph.adjacency(lending_2005, mode="undirected", weighted=TRUE)

plot(lending, 
     edge.width = igraph::E(lending)$weight*0.4)


```


### Importing the Data

The `GERGM` package does things in its own way with its own environment, it does not rely either on `igraph` not `network` formats. 
Hence, you need to pass row data (weighted adjacency matrices and data frames) to this model. 


Let's inspect the weighted adjacency matrix.

```{r weight02, exercise = TRUE, exercise.setup = "weightloadData"}

lending_2005

```


and also the covariates

```{r weight03, exercise = TRUE, exercise.setup = "weightloadData"}
covariate_data_2005
```



### Running a weighted ERGM

Ok, let's move on with this research using our seven-steps flow. 

#### Step one (Theory/Questions/Hypotheses)

As usual, let's assume that we are experts in international trade and fully aware of this stream of research so that we can already formulate hypotheses. 

* 1. trade is mutual (If country A sells and buy to/from B, B sells and buy to/from A)
* 2. The GDP is associated with the probability of sending more money (high weight ties)
* 3. The GDP is associated with the probability of receiving more money (high weight ties)

#### Term Specicifation
The terms are a bit different than the `ergm` package, but not that much.

* 1. `mutual`
* 2. `sender`
* 3. `receiver`

Unlike the `ergm` set up, in the `GERGM` one, we can attach an attribute to the sender and receiver effects.

### Step two (Data Exploration)


Let's explore the covariates we have in our data set.


```{r weight04, exercise = TRUE, exercise.setup = "weightloadData"}

head(covariate_data_2005)


```

We have three covariates. Our hypotheses require us to focus on GDP. Since the GDP is really high, it is convenient to work with its log function.


```{r weight05, exercise = TRUE, exercise.setup = "weightloadData"}
class(covariate_data_2005$log_GDP)
```



Ok, now we know how to specify the model. Don't we?

#### Step three (model specification)

Let's start with the baseline. If we don't specify any option in `edges`, it will work as it does in the `ergm` package. We can also decide to include an intercept in the weighted part of the model. We specify the second option using `edges(method = "regression")` if we want to do so. Why don't you try to see what happens?

Note1: In the `GERGM` environment, you specify the formula of the ERGM before running the model. 

Note2: In the `GERGM` environment, a baseline model with `edges` only does not work. Hence, try directly with the other variables.

NOTE3: This model might be too heavy to run in your tutorial, depending on your computer. If it does not run, run it on `Rstudio` directly. You can load the data using the `data` function. 

`data("lending_2005", package = "GERGM")`

`data("covariate_data_2005", package = "GERGM")`


As you can see in the specification, this data set is located in the `GERGM` package itself. 


_ALERT:_

THIS MODEL USES PARALLELIZATION. CHECK YOUR NUMBER OF CORES BEFORE RUNNING. 

If you have more than three cores, you can increase the number below and make it faster.

```{r weight06, exercise = TRUE, exercise.setup = "weightloadData"}
formula0 <- lending_2005 ~ edges + mutual


m0 <- GERGM::gergm(formula0,
                   covariate_data = covariate_data_2005,
                   number_of_networks_to_simulate = 5000,
                   thin = 1/100,
                   proposal_variance = 0.05,
                   MCMC_burnin = 1000,
                   seed = 456,
                   convergence_tolerance = 0.5, 
                   parallel = TRUE,
                   cores = 3)
```


Why don't you run other exploratory models here by trying some other terms? I give you the final one below, but first try to play a little (keep the number of cores in the parallelization in  mind!) :)

_NOTE:_
I inserted a burn-in of 1000 and simulated 5000 networks. I used this set up to speed up computation within the tutorial. You will need to increase these numbers to something like 10k and 40k (or more) when you will use these models for real!


Let's move on with another model!

_ALERT:_

THIS MODEL USES PARALLELIZATION. CHECK YOUR NUMBER OF CORES BEFORE RUNNING. 

If you have more than _three_ cores, you can increase the number below and make it faster.

```{r weight07, exercise = TRUE, exercise.setup = "weightloadData"}
formula1 <- lending_2005 ~ edges + sender("log_GDP")


m1 <- GERGM::gergm(formula1,
                   covariate_data = covariate_data_2005,
                   number_of_networks_to_simulate = 5000,
                   thin = 1/100,
                   proposal_variance = 0.05,
                   MCMC_burnin = 1000,
                   seed = 456,
                   convergence_tolerance = 0.5,
                   parallel = TRUE,
                   cores = 3)
```


_NOTE:_
I inserted a burn-in of 1000 and simulated 5000 networks. I used this set up to speed up computation within the tutorial. You will need to increase these numbers to something like 10k and 40k (or more) when you will use these models for real!



Ok, let's get to our final model. 



_ALERT:_

THIS MODEL USES PARALLELIZATION. CHECK YOUR NUMBER OF CORES BEFORE RUNNING. 

If you have more than two cores, you can increase the number below and make it faster.

```{r weight08, exercise = TRUE, exercise.setup = "weightloadData"}
formula2 <- lending_2005 ~ edges + mutual(alpha = 0.8) + sender("log_GDP") + 
  receiver("log_GDP")

m2 <- GERGM::gergm(formula2,
                   covariate_data = covariate_data_2005,
                   number_of_networks_to_simulate = 5000,
                   thin = 1/100,
                   proposal_variance = 0.05,
                   MCMC_burnin = 1000,
                   seed = 456,
                   convergence_tolerance = 0.5,
                   parallel = TRUE,
                   cores = 2)
```


_NOTE:_
I inserted a burn-in of 1000 and simulated 5000 networks. I used this set up to speed up computation within the tutorial. You will need to increase these numbers to something like 10k and 40k (or more) when you will use these models for real!


Is this model good enough? Let's analyse the diagnostics!


#### Step four (MCMC diagnostics)

Even if the `GERGM` models automatically prints info about the quality of the model, it is possible to reprint them separately too. 

Here we can reprint and observe the MCMC diagnostics.

```{r weight09, exercise = TRUE, exercise.setup = "weight08"}
GERGM::Trace_Plot(m2)
```


Since this model is different from the regular ERGM, the trace plot doesn't need to be centered at 0. Instead, there is a black line telling you where the trace plot should be centered. Does this look good to you? 

```{r testquiz, echo = FALSE}
learnr::quiz(learnr::question("Does the trace plot look good to you?",
                              learnr::answer("Yes, the spikes are reaching the bottom and the top of the plot,"),
                              learnr::answer("A bit, the chain is mixing well, and the several iteraition of the simulation vary smoothly "),
                              learnr::answer("No, the chain is not mixing well, and the plot is not centered on the black line", correct = TRUE), 
                              correct = "Yes! Well done!",
                              random_answer_order = TRUE,
                              allow_retry = TRUE))

```



```{r test_testquiz1, results = 'markup'}

q1 <- learnr::quiz(learnr::question("Does the trace plot look good to you?",
                              learnr::answer("Yes, the spikes are reaching the bottom and the top of the plot,"),
                              learnr::answer("A bit, the chain is mixing well, and the several iteraition of the simulation vary smoothly "),
                              learnr::answer("No, the chain is not mixing well, and the plot is not centered on the black line", correct = TRUE), 
                              correct = "Yes! Well done!",
                              random_answer_order = TRUE,
                              allow_retry = TRUE))


if (base::isFALSE(q1$questions[[1]]$question == "Does the trace plot look good to you?")) {
  sna4tutti::broken_info()
  error <- knitr::opts_current$get(name = "label")
  errors <- base::append(errors, error)
}


```


```{r test_testquiz2, results = 'markup'}
# test correct answer
q1in <- learnr::question("Does the trace plot look good to you?",
                              learnr::answer("Yes, the spikes are reaching the bottom and the top of the plot,"),
                              learnr::answer("A bit, the chain is mixing well, and the several iteraition of the simulation vary smoothly "),
                              learnr::answer("No, the chain is not mixing well, and the plot is not centered on the black line", correct = TRUE))


if (base::isFALSE(q1in$answers[[3]]$correct)) {
  sna4tutti::broken_info()
  error <- knitr::opts_current$get(name = "label")
  errors <- base::append(errors, error)
  
}

```

Since our MCMC diagnostics are not good enough, let's move on to the GOF, just to learn how to look at it!


#### Step five (Goodness of Fit)

Same story for the goodness of fit. Even if the models produce it automatically, you can recall it this way.

```{r weight10, exercise = TRUE, exercise.setup = "weight08"}

GERGM::GOF(m2)
```

```{r testquiz1, echo = FALSE}
learnr::quiz(learnr::question("Does this fit look good?? ",
                      learnr::answer("Yes, since the observed mean match with the simulated ones"),
                      learnr::answer("A bit, since the observed mean match with the simulated ones most of the time but not always", correct = TRUE),
                      learnr::answer("No, since the observed mean never match with the simulated ones"), 
                      correct = "Yes! Good!!",
                      random_answer_order = TRUE,
                      allow_retry = TRUE)
)
```


```{r test_testquiz11, results = 'markup'}

q1 <- learnr::quiz(learnr::question("Does this fit look good??",
                      learnr::answer("Yes, since the observed mean match with the simulated ones"),
                      learnr::answer("A bit, since the observed mean match with the simulated ones most of the time but not always", correct = TRUE),
                      learnr::answer("No, since the observed mean never match with the simulated ones"), 
                      correct = "Yes! Good!!",
                      random_answer_order = TRUE,
                      allow_retry = TRUE))


if (base::isFALSE(q1$questions[[1]]$question == "Does this fit look good??")) {
  sna4tutti::broken_info()
  error <- knitr::opts_current$get(name = "label")
  errors <- base::append(errors, error)
}


```


```{r test_testquiz12, results = 'markup'}
# test correct answer
q1in <- learnr::question("Does this fit look good??",
                      learnr::answer("Yes, since the observed mean match with the simulated ones"),
                      learnr::answer("A bit, since the observed mean match with the simulated ones most of the time but not always", correct = TRUE),
                      learnr::answer("No, since the observed mean never match with the simulated ones"))


if (base::isFALSE(q1in$answers[[2]]$correct)) {
  sna4tutti::broken_info()
  error <- knitr::opts_current$get(name = "label")
  errors <- base::append(errors, error)
  
}

```

The MCMC diagnostics and GOF in this model are not the best. It might be due to the small size of the simulation. Hence, if this happens to you, try to increase the burn-in and the number of chains before trashing the entire model. However, this cannot be done within the tutorial. Play around with these models in your Rstudio environment. Here is the code to load the data, again :)

`data("lending_2005", package = "GERGM")`

`data("covariate_data_2005", package = "GERGM")`



#### Step Six 

How about the results? Well, this model is pretty bad, but let's learn how to explore them anyway, pretending that it is ok!

The package already provides an inbuilt estimates plot. Red means significant, while the other colors mean the opposite. But a table with coefficient could be nice too, right? Here we go.

```{r weight11, exercise = TRUE, exercise.setup = "weight08"}

GERGM::Estimate_Plot(m2)

(EstSE <- rbind(t(attributes(m2)$theta.coef),
               t(attributes(m2)$lambda.coef)))

```

Mutual is not significant so, apparently, trade is a one-way operation. But sender and receiver for what concerns GDP are! It seems that if we take GDP into account, we can predict the intensity of the trade relationship (the weight of the edge). In fact, here, we don't only predict the existence of an edge but also the strength of the edge. GDP seems to be positively associated with trade. Countries with higher GDP trade more, both are sending and receiving goods. It makes sense, right? 

How much does GDP influence the relationships between nodes? Well, up to you to check odds ratios and probabilities to find out :)


## Conclusion

Our magical mystery tour is coming to an end. Now you can fly back home like a rocket with your advanced ERGM graduation hat!

Be ready to jump into a time machine with temporal ERGM (TERGM) next week!

![](images/Rocket-Dog.jpg){width=75%}




```{r check_results, echo = FALSE, results = 'markup'}
cat("\n\n\n\n\n\n")

if (length(errors) > 0) {
  cat("There were issues with the following chunk(s):\n\n")
  print(unlist(errors))
  cat("\n\n")
  cat("Please contact Claudia and Roger with this info!\n")
}

```



```{r check_results_external, echo=FALSE, child = if (length(errors) > 0) "check_results.Rmd"}
```
